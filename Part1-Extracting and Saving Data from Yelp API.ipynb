{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8guYh-VR7nlX"
   },
   "source": [
    "# Part 1 - Extracting and Saving Data from Yelp API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8guYh-VR7nlX"
   },
   "source": [
    "- For this CodeAlong, we will be working with the Yelp API. \n",
    "- You will use the the Yelp API to search your home town for a cuisine type of your choice.\n",
    "- Next class, we will then use Plotly Express to create a map with the Mapbox API to visualize the results.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8guYh-VR7nlX"
   },
   "source": [
    "## Tools You Will Use\n",
    "- Part 1:\n",
    "    - Yelp API:\n",
    "        - Getting Started: \n",
    "            - https://www.yelp.com/developers/documentation/v3/get_started\n",
    "\n",
    "    - `YelpAPI` python package\n",
    "        -  \"YelpAPI\": https://github.com/gfairchild/yelpapi\n",
    "- Part 2:\n",
    "\n",
    "    - Plotly Express: https://plotly.com/python/getting-started/\n",
    "        - With Mapbox API: https://www.mapbox.com/\n",
    "        - `px.scatter_mapbox` [Documentation](https://plotly.com/python/scattermapbox/): \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Code From\n",
    "- Efficient API Calls Lesson Link: https://login.codingdojo.com/m/376/12529/88078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "from yelpapi import YelpAPI\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yelpapi --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l3Z-79nBSX9"
   },
   "source": [
    "## 1. Registering for Required APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l3Z-79nBSX9"
   },
   "source": [
    "\n",
    "- Yelp: https://www.yelp.com/developers/documentation/v3/get_started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check the official API documentation to know what arguments we can search for: https://www.yelp.com/developers/documentation/v3/business_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Credentials and Create Yelp API Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T18:20:46.629934Z",
     "start_time": "2022-03-25T18:20:45.915864Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJYqVvNkE36a",
    "outputId": "67798160-dea2-41fc-9040-2b3833efa560"
   },
   "outputs": [],
   "source": [
    "# Load API Credentials\n",
    "relative_path = os.path.join('.secret', 'yelp_api.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate YelpAPI Variable\n",
    "with open('.secret/yelp_api.json') as file:\n",
    "    yelp_credentials = json.load(file)\n",
    "    \n",
    "yelp_api = YelpAPI(yelp_credentials['api-key'], timeout_s=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: D:\\My Documents\\GitHub\\data-enrichment-wk14-activity-mapping-yelp-api-results\n",
      "Contents of .secret directory: ['yelp_api.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# List the contents of the '.secret' directory\n",
    "try:\n",
    "    print(\"Contents of .secret directory:\", os.listdir('.secret'))\n",
    "except FileNotFoundError:\n",
    "    print(\".secret directory not found.\")\n",
    "\n",
    "# Attempt to open the file\n",
    "try:\n",
    "    with open('.secret/yelp_api.json') as f:\n",
    "        # Your file reading code here\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    print(\"The file '.secret/yelp_api.json' was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Rename the file from 'yelp_api.json.txt' to 'yelp_api.json'\n",
    "# os.rename('.secret/yelp_api.json.txt', '.secret/yelp_api.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: D:\\My Documents\\GitHub\\data-enrichment-wk14-activity-mapping-yelp-api-results\n",
      "Contents of .secret directory: ['yelp_api.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# List the contents of the '.secret' directory\n",
    "try:\n",
    "    print(\"Contents of .secret directory:\", os.listdir('.secret'))\n",
    "except FileNotFoundError:\n",
    "    print(\".secret directory not found.\")\n",
    "\n",
    "# Attempt to open the file\n",
    "try:\n",
    "    with open('.secret/yelp_api.json') as f:\n",
    "        # Your file reading code here\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    print(\"The file '.secret/yelp_api.json' was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate YelpAPI Variable\n",
    "with open('.secret/yelp_api.json') as file:\n",
    "    yelp_credentials = json.load(file)\n",
    "    \n",
    "yelp_api = YelpAPI(yelp_credentials['api-key'], timeout_s=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Search Terms and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be saved to: /Data/results_SC_Sushi.json\n"
     ]
    }
   ],
   "source": [
    "# Define API call parameters and output file path\n",
    "LOCATION = 'Greenville, SC'\n",
    "TERM = 'Sushi'\n",
    "JSON_FILE = '/Data/results_SC_Sushi.json'\n",
    "\n",
    "# Display the file path where data will be saved\n",
    "print(f'Data will be saved to: {JSON_FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Json File exists and Create it if it doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] /Data/results_SC_Sushi.json already exists.\n"
     ]
    }
   ],
   "source": [
    "# Check if JSON_FILE exists and create it if it doesn't\n",
    "if not os.path.isfile(JSON_FILE):\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(JSON_FILE), exist_ok=True)\n",
    "    \n",
    "    # Inform user and save an empty list to file\n",
    "    print(f'[i] {JSON_FILE} not found. Saving empty list to file.')\n",
    "    with open(JSON_FILE, 'w') as file:\n",
    "        json.dump([], file)\n",
    "else:\n",
    "    # Inform user if the file already exists\n",
    "    print(f'[i] {JSON_FILE} already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JSON FIle and account for previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 previous results found.\n"
     ]
    }
   ],
   "source": [
    "# Load previous results and set offset based on the number of results\n",
    "with open(JSON_FILE, 'r') as file:\n",
    "    previous_results = json.load(file)\n",
    "\n",
    "n_results = len(previous_results)\n",
    "\n",
    "print(f'- {n_results} previous results found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the first API call to get the first page of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use this first result to check:\n",
    "    - how many total results there are?\n",
    "    - Where is the actual data we want to save?\n",
    "    - how many results do we get at a time?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['businesses', 'total', 'region'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location = LOCATION,\n",
    "                                term = TERM,\n",
    "                                offset = n_results)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T20:01:48.867510Z",
     "start_time": "2022-03-24T20:01:48.854746Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Myur3i1KGhPf",
    "outputId": "f447c6f9-596b-41d0-ccda-50af0ce82108"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many results total?\n",
    "total_results = results['total']\n",
    "total_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Where is the actual data we want to save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_data = results['businesses']\n",
    "\n",
    "# specify the filename where you want to save the data\n",
    "json_file_path = JSON_FILE\n",
    "\n",
    "# save the business data to a JSON file\n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump(business_data, file, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of results retrieved per page 20\n"
     ]
    }
   ],
   "source": [
    "## How many did we get the details for?\n",
    "results_per_page = len(business_data)\n",
    "print(f'number of results retrieved per page', results_per_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate how many pages of results needed to cover the total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages: 6\n"
     ]
    }
   ],
   "source": [
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil(total_results / results_per_page)\n",
    "print(f'Total number of pages: {n_pages}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = yelp_api.search_query(location=LOCATION, term=TERM, offset=n_results)\n",
    "\n",
    "total_results = results['total']\n",
    "business_data = results['businesses']\n",
    "\n",
    "with open(JSON_FILE, 'w') as file:\n",
    "    json.dump(business_data, file, indent=4)\n",
    "\n",
    "results_per_page = len(business_data)\n",
    "\n",
    "# Check if there are any results per page to avoid division by zero\n",
    "if results_per_page > 0:\n",
    "    n_pages = math.ceil(total_results / results_per_page)\n",
    "else:\n",
    "    n_pages = 0  # No pages if there are no results\n",
    "\n",
    "print(f'Number of results retrieved per page: {results_per_page}')\n",
    "print(f'Total number of pages: {n_pages}')\n",
    "\n",
    "# Additional handling for when there are no business results\n",
    "if n_pages == 0:\n",
    "    print(\"No business data found for the given search parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `results_per_call` and `total_iterations` are correctly calculated before this snippet.\n",
    "for i in tqdm_notebook(range(1, total_results + 1)):\n",
    "    try:\n",
    "        time.sleep(0.2)  # Short delay to respect API rate limits\n",
    "        \n",
    "        # Load existing results to append new data\n",
    "        with open(JSON_FILE, 'r') as file:\n",
    "            previous_results = json.load(file)\n",
    "\n",
    "        # Fetch new results using the current length of previous_results as the offset\n",
    "        new_results = yelp_api.search_query(location=LOCATION, term=TERM, offset=len(previous_results))\n",
    "\n",
    "        # Append and save the updated results\n",
    "        updated_results = previous_results + new_results['businesses']\n",
    "        with open(JSON_FILE, 'w') as file:\n",
    "            json.dump(updated_results, file)\n",
    "\n",
    "    except Exception as e:\n",
    "        if 'Too Many Requests for url' in str(e):\n",
    "            print('Rate limit exceeded. Stopping data collection.')\n",
    "            break  # Exit loop if rate limit is exceeded\n",
    "        else:\n",
    "            print(f'An error occurred: {e}')\n",
    "            continue  # Continue to next iteration in case of other errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the Final JSON File with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final JSON file into a DataFrame\n",
    "df = pd.read_json(JSON_FILE)\n",
    "\n",
    "# Display the first and last few rows of the DataFrame\n",
    "display(df.head(), df.tail())\n",
    "\n",
    "# Check for duplicate entries based on the 'id' column\n",
    "duplicate_count = df.duplicated(subset='id').sum()\n",
    "print('\\n')\n",
    "print(f'Number of duplicate IDs: {duplicate_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory and base filename\n",
    "directory = 'Data'\n",
    "filename = 'final_results_SC_Sushi.csv.gz'  # Include .csv.gz extension here\n",
    "path = os.path.join(directory, filename)\n",
    "\n",
    "# Ensure that the 'Data' directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save DataFrame as a compressed CSV file (to save space)\n",
    "df.to_csv(path, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the correct JSON file name\n",
    "json_file = 'Data/final_results_SC_Sushi.json'\n",
    "\n",
    "# Save the DataFrame as JSON with optimal orientation for line-delimited JSON\n",
    "df.to_json(json_file, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and Save as .CSV.GZ by replacing the file extension\n",
    "csv_gz_file = json_file.replace('.json', '.csv.gz')\n",
    "\n",
    "# Save the DataFrame as a compressed CSV without the index\n",
    "df.to_csv(csv_gz_file, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: compare filesize with os module's `os.path.getsize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare File Sizes to demonstrate the efficiency of compression\n",
    "if os.path.exists(json_file) and os.path.exists(csv_gz_file):\n",
    "    size_json = os.path.getsize(json_file)\n",
    "    size_csv_gz = os.path.getsize(csv_gz_file)\n",
    "\n",
    "    print(f'JSON FILE: {size_json:,} Bytes')\n",
    "    print(f'CSV.GZ FILE: {size_csv_gz:,} Bytes')\n",
    "\n",
    "    # Calculate and display the compression ratio if the .csv.gz file is not empty\n",
    "    if size_csv_gz > 0:\n",
    "        compression_ratio = size_json / size_csv_gz\n",
    "        print(f'The csv.gz file is {compression_ratio:.2f} times smaller than the JSON file.')\n",
    "    else:\n",
    "        print(\"CSV.GZ file size is 0, cannot compare sizes.\")\n",
    "else:\n",
    "    print(\"One or both files do not exist, check file paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Class: Processing the Results and Mapping "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test Yelp API Package.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
